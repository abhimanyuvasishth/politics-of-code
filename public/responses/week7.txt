Our Facebook news feed is a form of mass media that we are in continuous contact with, and this week's reading deals with the algorithm that governs the news feed, the spreading of trends through Facebook connections, and the powers at play. 'Who controls your Facebook feed?' highlights the potential shortcomings of the news feed algorithm. On the face of it, the algorithm is data driven. There are hundreds of features that govern the rank order of stories on your news feed. But there are humans that choose the data, and the parameters, and what the results should be. And the measure of the success of the algorithm is in the currency of likes and clicks. But these measures are so vague, and almost always end up filling up your news feed with similar stories, that are engineered to go viral. Now, although Facebook asks for qualitative feedback from real human users, their algorithm is still concealed within a black box, and the success rate is still not great. 'What Facebook knows' illustrates this conundrum in the context of generating ad revenue. “The biggest challenges Facebook has to solve are the same challenges that social science has,” says Cameron Marlow, a former Facebook data scientist. Their endeavour is to see what trends are becoming popular and how fashion spreads between members of this vast social network, and while doing so, show users content that they can make money of and that is of interest to the users. The market for online ads is dwindling, and Facebook must find a way of staying ahead of trends in order to optimize online advertising. Another interesting observation that Marlow made is that although our close friends have a large impact of information that we comment on, like, and share, their impact on our news feed is small compared to the larger pool of "weak ties," a network of numerous distant contacts. The influence of a small local population on creating the illusion of a global trend is an idea proposed by the authors of 'The Majority Illusion.' They illustrate this concept by changing the neighbouring nodes of a node in a network, giving the average Facebook user the impression that a lot of her/his friends are into something when there is clear selection bias in the posts that are visible to her/him. In the context of Facebook's news feed, two of the five filters of editorial bias are particularly relevant. First, Facebook is a for-profit organization and their engineers can control what kids of content makes it to your news feed and what does not make it; and that Facebook's business model is entirely ad-centric, so they will end up catering to the political views and desires of their investors and advertisers. So your Facebook news feed is not exactly the crowd-sourced journalism platform you had initially envisioned.